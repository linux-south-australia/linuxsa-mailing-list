<HTML>
<!-- EmailData="Start" -->
<!-- Version="1.1" -->
<!-- Subject="Re: Log files > SQL db" -->
<!-- FromName="'John Edwards'" -->
<!-- FromEmail="isplist@pinnacle.net.au" -->
<!-- ToName="'Matthew Geddes'" -->
<!-- ToEmail="mgeddes@xavier.sa.edu.au" -->
<!-- Date="Mon, 05 Feb 2001 12:43:48 +1030" -->
<!-- Id="3A7E0C5C.5716C4F3@pinnacle.net.au" -->
<!-- Reference="3A7E049F.E615FA39@xavier.sa.edu.au" -->
<!-- X-Face="" -->
<!-- X-URL="" -->
<!-- EmailData="End" -->
<HEAD>
<TITLE>LinuxSA Mailing List: Re: Log files &gt; SQL db</TITLE>
</HEAD>
<BODY BGCOLOR=#FFFFFF><H1>LinuxSA Mailing list archives</H1>
<!-- IndexControl1="Start" -->
Index:
[<A HREF="thread.html">thread</A>]
[<A HREF="date.html">date</A>]
[<A HREF="subject.html">subject</A>]
[<A HREF="author.html">author</A>]
[<A HREF="stats.html">stats</A>]
<HR>
<!-- IndexControl1="End" -->
<!-- Header="Start" -->
<PRE>
  From: John Edwards &lt;<I><A HREF="mailto:isplist@pinnacle.net.au">isplist@pinnacle.net.au</A></I>&gt;
  To  : Matthew Geddes &lt;<I><A HREF="mailto:mgeddes@xavier.sa.edu.au">mgeddes@xavier.sa.edu.au</A></I>&gt;
  Date: Mon, 05 Feb 2001 12:43:48 +1030
</PRE>
<H1>Re: Log files &gt; SQL db</H1>
<!-- Header="End" -->
<!-- Body="Start" -->
<PRE>
Matthew Geddes wrote:
 
&gt; I've got a program (squid) that outputs a rather large log file. I'd
&gt; like to get the data from that log file into an SQL database without
&gt; having to:
&gt; 
&gt;         a) edit and recompile squid (squid's stable and I don't want to
&gt; accidentally change that ;-))
&gt;         b) have a perl script constantly polling an 800MB text file ;-)

Squid has a rotate_logs option that allows you to do a squid -k rotate
to rename the current log and start a new one. 800Mb of squid access log
sounds like around a month's worth of requests .. do you need it to be
realtime, or would a daily/hourly batch job be good enough?

Also, once you start talking about millions of lines of logs like this
(daily!), perhaps an SQL database isn't the way to go. a custom-written
perl program that only needs to read the data from disk once to get all
the stats it needs will be a lot kinder on your system than an series of
SQL statements that hit the data AND indexes each time a query is run,
unless you have enough ram to cache the lot.

John Edwards

-- 
LinuxSA WWW: <A HREF="http://www.linuxsa.org.au/">http://www.linuxsa.org.au/</A>  IRC: #linuxsa on irc.linux.org.au
To unsubscribe from the LinuxSA list:
  mail <A HREF="mailto:linuxsa-request@linuxsa.org.au">linuxsa-request@linuxsa.org.au</A> with "unsubscribe" as the subject

</PRE>
<!-- Body="End" -->
<!-- IndexControl2="Start" -->
<HR>
Index:
[<A HREF="thread.html">thread</A>]
[<A HREF="date.html">date</A>]
[<A HREF="subject.html">subject</A>]
[<A HREF="author.html">author</A>]
[<A HREF="stats.html">stats</A>]
<!-- IndexControl2="End" -->
<HR><FONT SIZE=+1>Return to the <A HREF=/mailing-list/>LinuxSA Mailing List Information</A> Page</FONT></BODY>
</HTML>
