<HTML>
<!-- EmailData="Start" -->
<!-- Version="1.1" -->
<!-- Subject="Re: Boosting NFS performance (bottlenecks?)" -->
<!-- FromName="'Paul Schulz'" -->
<!-- FromEmail="paul@mawsonlakes.org" -->
<!-- ToName="'Ryan Verner'" -->
<!-- ToEmail="xfesty@computeraddictions.com.au" -->
<!-- Date="Thu, 12 Feb 2004 08:29:09 +1030" -->
<!-- Id="1076536749.10364.12.camel@localhost" -->
<!-- Reference="Pine.LNX.4.44.0402111056550.6619-100000@durable" -->
<!-- X-Face="" -->
<!-- X-URL="" -->
<!-- EmailData="End" -->
<HEAD>
<TITLE>LinuxSA Mailing List: Re: Boosting NFS performance (bottlenecks?)</TITLE>
</HEAD>
<BODY BGCOLOR=#FFFFFF><H1>LinuxSA Mailing list archives</H1>
<!-- IndexControl1="Start" -->
Index:
[<A HREF="thread.html">thread</A>]
[<A HREF="date.html">date</A>]
[<A HREF="subject.html">subject</A>]
[<A HREF="author.html">author</A>]
[<A HREF="stats.html">stats</A>]
<HR>
<!-- IndexControl1="End" -->
<!-- Header="Start" -->
<PRE>
  From: Paul Schulz &lt;<I><A HREF="mailto:paul@mawsonlakes.org">paul@mawsonlakes.org</A></I>&gt;
  To  : Ryan Verner &lt;<I><A HREF="mailto:xfesty@computeraddictions.com.au">xfesty@computeraddictions.com.au</A></I>&gt;
  Date: Thu, 12 Feb 2004 08:29:09 +1030
</PRE>
<H1>Re: Boosting NFS performance (bottlenecks?)</H1>
<!-- Header="End" -->
<!-- Body="Start" -->
<PRE>
Ryan,

On issue in the past has been the NFS throughput between
Linux and Sun Solaris.
(I believe Rusty gave a description of this problem at a LinuxSA meeting
a couple of years ago..)

The problem is that NFS packets are very large (larger that the MTU)
and are fragmented by the IP layer. 

- Linux, sends out fragments in reverse order, which (usually)  
  speeds up processing time to send and receive, when done between 
  two Linux boxes.

- Solaris stored fragments in a data structure that   
  would add fragments to the end until all had been received and 
  the packet restored. If fragments were received out of order,
  Solaris would rebuild the data structure to put the new fragment
  at the start.

This may be the case with other UNIX's.
Solution..? I'd have a look at the Linux kernel config to see 
if there is a way of turning off the 'set out fragments in reverse'.
(I can't remember there being one though.)

Cheers,
Paul

On Thu, 2004-02-12 at 05:32, Richard Sharpe wrote:
&gt; On Thu, 12 Feb 2004, Ryan Verner wrote:
&gt; 
&gt; &gt; 
&gt; &gt; On 12/02/2004, at 1:47 AM, Ryan Verner wrote:
&gt; &gt; 
&gt; &gt; &gt; On 12/02/2004, at 1:35 AM, Ryan Verner wrote:
&gt; &gt; &gt;&gt; 100baseTX full-duplex, I'm only getting ~10MB/sec transfers.  I 
&gt; &gt; &gt;&gt; actually need much
&gt; &gt; &gt;
&gt; &gt; &gt; Erm, 1000baseTX full-duplex, even.  10MB/sec would be good @ the lower 
&gt; &gt; &gt; speed, but unfortunately for this, it isn't *quite* enough juice.
&gt; &gt; 
&gt; &gt; And just to follow up myself again, that 10MB/sec was a once off, I 
&gt; &gt; think - I'm getting averages of around 5MB/sec, which is what I would 
&gt; &gt; expect for 100baseTX.  Cards are definitely running at 1000baseTX 
&gt; &gt; full-duplex, though.
&gt; &gt; 
&gt; &gt; What kind of speeds should I expect?
&gt; &gt; 
&gt; &gt; I know that the G5 isn't a bottleneck as it's also connected to an 
&gt; &gt; XServe RAID via fibre channel, and it transfers to/from this at 
&gt; &gt; absolute insane speeds.
&gt; &gt; 
&gt; &gt; I just converted one filesystem to XFS, and as I suspected, it made 
&gt; &gt; absolutely no difference to transfer speeds.
&gt; &gt; 
&gt; &gt; Argh.  Anybody want to suggest anything?  :-(
&gt; 
&gt; We came across an interesting bug in the FreeBSD NFS server code in 4.6.2 
&gt; which was still in the code all the way to 5.x. This bug only affected 
&gt; server code, so I don't know if it is what you are seeing.
&gt; 
&gt; The server code only allocated socket buffer space (this was TCP, BTW), of 
&gt; 32kB plus a bit for the RPC overhead. The client was doing 64kB reads. 
&gt; The first 32kB went out, but the second 32kB was not sent until the Linux 
&gt; client acked the very last segment of the first 32kB. This caused long 
&gt; pauses in the middle (something like 32ms) and reduced throughput to 
&gt; something like 6MB/s. Today we can get 70+MB/s. The problem was that the 
&gt; in-kernel NFS server was using kernel routines that would not put any data 
&gt; in the socket buffer until all the space needed was there. Since the last 
&gt; segment of the last 32kB was still in the socket buffer, there was not 
&gt; room for another 32kB + header space.
&gt; 
&gt; You can check for these problems by grabbing a capture and looking at it 
&gt; with the Analyse--&gt;Tcp Stream Analysis--&gt;tcptrace type and look for a 
&gt; marked staircase effect in the graph.
&gt; 
&gt; Regards
&gt; -----
&gt; Richard Sharpe, rsharpe[at]richardsharpe.com, rsharpe[at]samba.org, 
&gt; sharpe[at]ethereal.com, <A HREF="http://www.richardsharpe.com">http://www.richardsharpe.com</A>

<A HREF="588_signature.asc">signature.asc</A>
-- 
LinuxSA WWW: <A HREF="http://www.linuxsa.org.au/">http://www.linuxsa.org.au/</A> IRC: #linuxsa on irc.freenode.net
To unsubscribe from the LinuxSA list:
  mail <A HREF="mailto:linuxsa-request@linuxsa.org.au">linuxsa-request@linuxsa.org.au</A> with "unsubscribe" as the subject

</PRE>
<!-- Body="End" -->
<!-- IndexControl2="Start" -->
<HR>
Index:
[<A HREF="thread.html">thread</A>]
[<A HREF="date.html">date</A>]
[<A HREF="subject.html">subject</A>]
[<A HREF="author.html">author</A>]
[<A HREF="stats.html">stats</A>]
<!-- IndexControl2="End" -->
<HR><FONT SIZE=+1>Return to the <A HREF=/mailing-list/>LinuxSA Mailing List Information</A> Page</FONT></BODY>
</HTML>
