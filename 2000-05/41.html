<HTML>
<!-- EmailData="Start" -->
<!-- Version="1.1" -->
<!-- Subject="Re: how do you stop site-downloaders?" -->
<!-- FromName="Alan Kennington" -->
<!-- FromEmail="akenning@dog.topology.org" -->
<!-- ToName="Lachlan Cameron-Smith" -->
<!-- ToEmail="lachlan.cameronsmith@adelaide.edu.au" -->
<!-- Date="Tue, 2 May 2000 15:03:39 +091800" -->
<!-- Id="20000502150339.A23794@dog.topology.org" -->
<!-- Reference="390E62C8.D782A11E@adelaide.edu.au" -->
<!-- X-Face="" -->
<!-- X-URL="" -->
<!-- EmailData="End" -->
<HEAD>
<TITLE>LinuxSA Mailing List: Re: how do you stop site-downloaders?</TITLE>
</HEAD>
<BODY BGCOLOR=#FFFFFF><H1>LinuxSA Mailing list archives</H1>
<!-- IndexControl1="Start" -->
Index:
[<A HREF="thread.html">thread</A>]
[<A HREF="date.html">date</A>]
[<A HREF="subject.html">subject</A>]
[<A HREF="author.html">author</A>]
<HR>
<!-- IndexControl1="End" -->
<!-- Header="Start" -->
<PRE>
  From: Alan Kennington &lt;<I><A HREF="mailto:akenning@dog.topology.org">akenning@dog.topology.org</A></I>&gt;
  To  : Lachlan Cameron-Smith &lt;<I><A HREF="mailto:lachlan.cameronsmith@adelaide.edu.au">lachlan.cameronsmith@adelaide.edu.au</A></I>&gt;
  Date: Tue, 2 May 2000 15:03:39 +091800
</PRE>
<H1>Re: how do you stop site-downloaders?</H1>
<!-- Header="End" -->
<!-- Body="Start" -->
<PRE>
On Tue, May 02, 2000 at 02:38:24PM +0930, Lachlan Cameron-Smith wrote:
&gt; Hello,
&gt; 
&gt; If they're downloading the whole site they're probably using something
&gt; like wget (ie a robot) - perhaps you could configure robots.txt to not
&gt; allow connections to certain files / directories?
&gt; 

Nope.
Unfortunately, they completely ignored my robots.txt file,
as do some of the well-known search engines, like exodus,
if I remember correctly.

Real search engines respect the rules for robots - they exclude
stuff in the robots.txt file, and they fetch only one
file every 5 to 60 seconds, depending on the search engine.
Since a search engine gives a broad benefit to the net, I don't
mind them downloading everything which is not excluded by
my robots.txt file.

The fact that this Danish user only downloaded 12 MB rather than
the whole 50 MB probably means that they decided to
stop the download after 75 minutes to do something
else instead.

One thought that I had was to write a Perl script which parses the
Apache log file, and detects that someone has read 100 files
in one hour and just firewalls them out.
But I would want to remove the firewall rule after an hour,
which is difficult with ipfwadm.
And ideally I would like to just pinch off their access to, say,
9600 bits/sec for an hour or so. And if that doesn't work,
I'd like to drop them to 300 bits/sec (i.e. about 1984 vintage).

That's the ideal, but if there's no Apache module, I'll probably
write an interim script that reads the Apache log file that
runs "ipfwadm" on the miscreant - and then think about the
longer term solution(s).
Of course, I don't want to stop the real search engines, which
are characterized by good spacing between accesses and respect
for the robots.txt file.

Cheers,
Alan Kennington.

PS. Even though this issue only seems to apply to people with
a permanent modem connection at the moment, in 5 years time,
a much larger proportion of people are likely to have a
24 hours/day IP link to the home - in my opinion...

PPS.  REgarding the idea of using PHP (Matt's idea), I can
see that I could put in a re-write rule in the Apache
config file to redirect all accesses to a PHP script, which
maintains a simple database (maybe in a process rather than
a file) to record every IP host's usage, and then denies or delays
access according to a set of rules.
That would have the side effect of making everyone's link
turn from "file.html" into "php3/throttle.php3?file=file.html"
or something. Even using various tricks, the best I could do
would be "throttle/file.html" as the rewrite rule.
All things considered, I'd prefer an Apache module -- which
someone surely must have written already.
(Every other idea I come up with has been done already!)

-- 
LinuxSA WWW: <A HREF="http://www.linuxsa.org.au/">http://www.linuxsa.org.au/</A>  IRC: #linuxsa on irc.linux.org.au
To unsubscribe from the LinuxSA list:
  mail <A HREF="mailto:linuxsa-request@linuxsa.org.au">linuxsa-request@linuxsa.org.au</A> with "unsubscribe" as the subject

</PRE>
<!-- Body="End" -->
<!-- IndexControl2="Start" -->
<HR>
Index:
[<A HREF="thread.html">thread</A>]
[<A HREF="date.html">date</A>]
[<A HREF="subject.html">subject</A>]
[<A HREF="author.html">author</A>]
<!-- IndexControl2="End" -->
<HR><FONT SIZE=+1>Return to the <A HREF=/mailing-list/>LinuxSA Mailing List Information</A> Page</FONT></BODY>
</HTML>
